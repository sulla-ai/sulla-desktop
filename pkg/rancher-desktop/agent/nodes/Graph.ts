// Graph - LangGraph-style workflow orchestrator
// sits on the backend and processes the graphs

import type { AbortService } from '../services/AbortService';
import { throwIfAborted } from '../services/AbortService';
import { getWebSocketClientService } from '../services/WebSocketClientService';
import type { ChatMessage } from '../languagemodels/BaseLanguageModel';
import { SullaSettingsModel } from '../database/models/SullaSettingsModel';
import { 
  OverLordPlannerNode,
  InputHandlerNode,
  PlanRetrievalNode
} from './index';
import { PlannerNode } from './PlannerNode';
import { ReasoningNode } from './ReasoningNode';
import { ActionNode } from './ActionNode';
import { SkillCriticNode } from './SkillCriticNode';
import { OutputNode } from './OutputNode';

// ============================================================================
// CONFIGURATION CONSTANTS
// ============================================================================

// SkillGraph retry configuration
const MAX_PLANNER_RETRIES = 15;
const MAX_REASONING_RETRIES = 15;
const MAX_ACTION_LOOPS = 20;

// ============================================================================
// DEFAULT SETTINGS
// ============================================================================

const DEFAULT_WS_CHANNEL = 'dreaming-protocol';
const MAX_CONSECTUIVE_LOOP = 15;
const MAX_MESSAGES_IN_THREAD = 120;

// ============================================================================
// THREAD STATE INTERFACES
// ============================================================================

/**
 * SkillGraph-specific thread state interface
 * Extends BaseThreadState with SkillGraph-specific metadata properties
 */
export interface SkillGraphState extends BaseThreadState {
  metadata: BaseThreadState['metadata'] & {
    planRetrieval?: {
      intent: string;
      goal: string;
      complexity?: 'high' | 'medium' | 'low';
    };
    planner?: {
      goal: string;
      skill_focused: boolean;
      prd_generated: boolean;
    };
    /**
     * The PRD working document produced by PlannerNode.
     * Injected as the system prompt for ReasoningNode and ActionNode.
     * Only PlannerNode writes to this field.
     */
    planning_instructions?: string;
    /**
     * Per-cycle technical instructions generated by ReasoningNode.
     * ActionNode consumes this as the execution directive.
     */
    technical_instructions?: string;
    reasoning?: {
      textPlan?: string;
    };
    actions?: Array<{
      success: boolean;
      result: any;
      evidence_collected?: Array<{
        evidence_type: string;
        description: string;
        evidence_pointer?: string;
        verification_method: string;
      }>;
      completion_justification?: string;
    }>;
    action?: {
      response?: string | null;
      updatedAt?: number;
    };
    skillCritic?: {
      technical_completed: boolean;
      technical_feedback: string;
      project_complete: boolean;
      project_feedback: string;
      evaluatedAt: number;
    };
    output?: {
      taskStatus: 'completed' | 'partial' | 'failed';
      completionScore: number;
      skillCompliance: number;
      summaryMessage: string;
      accomplishments: string[];
      evidenceHighlights: string[];
      nextSteps: string[];
      skillFeedback: string;
      generatedAt: number;
      cycleCount: number;
      actionCount: number;
      evidenceCount: number;
    };
    reactLoopCount?: number;
  };
}

/**
 * Generic node interface for any graph execution.
 * Nodes MUST ONLY write facts/verdicts to state — no routing decisions.
 * @template TState - Specific state shape (BaseThreadState, OverlordThreadState, etc.)
 */
export interface GraphNode<TState> {
  /** Unique node identifier (must be graph-unique, e.g. 'tactical_executor') */
  id: string;

  /** Human-readable name for logs/debug */
  name: string;

  /**
   * Core execution logic.
   * - Perform work (plan, execute, critique, write, etc.)
   * - Mutate state.metadata with results/facts only
   * - Return neutral decision (graph edges handle real next node)
   */
  execute(state: TState): Promise<NodeResult<TState>>;

  /** Optional: one-time setup (LLM init, tool registration, etc.) */
  initialize?(): Promise<void>;

  /** Optional: cleanup on graph destroy */
  destroy?(): Promise<void>;
}

/**
 * Minimal result type every node must return.
 * Keeps routing out of nodes — edges interpret state facts.
 */
export interface NodeResult<TState> {
  state: TState;                  // mutated/updated state
  decision: NodeDecision;         // neutral signal only
}

// NodeResult must always be one of:
type NodeDecision =
  | { type: 'end' }
  | { type: 'goto', nodeId: string }
  | { type: 'continue' }           // same node, more work
  | { type: 'next' }               // follow static/conditional edge
  | { type: 'revise' }             // go back to planner/critic

export interface GraphEdge<TState> {
  from: string;
  to: string | ((state: TState) => string | null);
}

// Base shared across all thread states
export interface BaseThreadState {
  messages: ChatMessage[];

  // for simple node
  prompt?: string;

  // Tools found by browse_tools calls (accumulates across multiple calls)
  foundTools?: any[];

  metadata: {
    action: 'direct_answer' | 'ask_clarification' | 'use_tools' | 'create_plan' | 'run_again';
    threadId: string;
    wsChannel: string;

    reasoning?: string;

    llmModel: string;
    llmLocal: boolean;

    cycleComplete: boolean;
    waitingForUser: boolean;

    options: {
      abort?: AbortService;
    };

    currentNodeId: string;
    consecutiveSameNode: number;
    iterations: number;
    revisionCount: number;
    maxIterationsReached: boolean;

    memory: {
      knowledgeBaseContext: string;
      chatSummariesContext: string;
    };

    // Plan retrieval data from PlanRetrievalNode - minimal metadata only
    // Skills and memories are now added to message thread via tool results
    planRetrieval?: {
      intent: string;
      goal: string;
      complexity?: 'high' | 'medium' | 'low';
    };

    // any graph could technically call another graph, this is the format
    subGraph: {
      state: 'trigger_subgraph' | 'running' | 'completed' | 'failed';
      name: 'hierarchical';
      prompt: string;
      response: string;
    };

    finalSummary: string;
    totalSummary?: string;
    finalState: 'failed'  | 'running' | 'completed';
    n8nLiveEventsEnabled?: boolean;

    // parent graph return
    returnTo: string | null;

    awarenessIncluded?: boolean;
    datetimeIncluded?: boolean;
    hadToolCalls?: boolean;
    hadUserMessages?: boolean;

    __pendingToolResults?: import('../types').PendingToolResult[];
  };
}

export interface OverlordThreadState extends BaseThreadState {
  messages: ChatMessage[];
  metadata: BaseThreadState['metadata'] & {

    // This is what the Overlord is going to be working on as it calls
    // other subgraphs
    primaryProject: string;
    projectDescription: string;
    projectGoals: string[];
    projectState: 'continue' | 'end';

  };
}

// ============================================================================
//
// Graph Class
//
//
//
// ============================================================================

/**
 * Generic Graph engine for hierarchical agent execution.
 * 
 * Supports any state shape via generics (TState).
 * - Nodes write facts/verdicts only
 * - Edges own all routing/advancement logic
 * - Handles abort, loop safety, WS completion signal
 * - Works standalone or as sub-graph (with returnTo flag)
 * 
 * Usage:
 *   const graph = new Graph<BaseThreadState>();
 *   graph.addNode(new InputHandlerNode());
 *   graph.setEntryPoint('input_handler');
 *   const finalState = await graph.execute(initialState);
 * 
 * @template TState - State interface (ThreadState, BaseThreadState, etc.)
 */
export class Graph<TState = BaseThreadState> {
  private nodes: Map<string, GraphNode<TState>> = new Map();
  private edges: Map<string, GraphEdge<TState>[]> = new Map();
  private entryPoint: string | null = null;
  private endPoints: Set<string> = new Set();
  private initialized = false;

  /**
   * Add a node to the graph.
   * @param node - Node instance implementing GraphNode<TState>
   * @returns this for chaining
   */
  addNode(node: GraphNode<TState>): this {
    this.nodes.set(node.id, node);
    return this;
  }

  /**
   * Add a static or conditional edge.
   * @param from - Starting node ID
   * @param to - Target node ID or conditional function (state => nextId | null)
   * @returns this for chaining
   */
  addEdge(
    from: string,
    to: string | ((state: TState) => string | null)
  ): this {
    const list = this.edges.get(from) || [];
    list.push({ from, to });
    this.edges.set(from, list);
    return this;
  }

  /**
   * Convenience alias for conditional edges.
   * @param from - Starting node ID
   * @param condition - Function returning next node ID or null
   * @returns this for chaining
   */
  addConditionalEdge(
    from: string,
    condition: (state: TState) => string | null
  ): this {
    return this.addEdge(from, condition);
  }

  /**
   * Set the starting node.
   * @param nodeId - Node ID to begin execution
   * @returns this for chaining
   */
  setEntryPoint(nodeId: string): this {
    this.entryPoint = nodeId;
    return this;
  }

  /**
   * Mark nodes as valid termination points.
   * @param nodeIds - Node IDs where execution can end
   * @returns this for chaining
   */
  setEndPoints(...nodeIds: string[]): this {
    nodeIds.forEach(id => this.endPoints.add(id));
    return this;
  }

  /**
   * Initialize all nodes (call initialize() if present).
   */
  async initialize(): Promise<void> {
    if (this.initialized) return;
    for (const node of this.nodes.values()) {
      if (node.initialize) await node.initialize();
    }
    this.initialized = true;
  }

  /**
   * Get node by ID for testing and validation purposes
   * @param nodeId - The node identifier
   * @returns The node instance or undefined if not found
   */
  getNode(nodeId: string): GraphNode<TState> | undefined {
    return this.nodes.get(nodeId);
  }

  /**
   * Get all node IDs for validation purposes
   * @returns Array of all registered node IDs
   */
  getNodeIds(): string[] {
    return Array.from(this.nodes.keys());
  }

  /**
   * Execute the graph from entry point until end or max iterations.
   * 
   * @param initialState - Starting state (TState)
   * @param maxIterations - Safety limit (default 1M)
   * @param options - Optional abort controller
   * @returns Final state after execution
   */
  async execute(
    initialState: TState,
    entryPointNodeId?: string,
    options?: { maxIterations: number }
  ): Promise<TState> {
    if (!this.entryPoint) throw new Error('No entry point');

    await this.initialize();

    let state = initialState;
    (state as any).metadata.currentNodeId = entryPointNodeId || this.entryPoint;

    console.log(`[Graph] Start from ${(state as any).metadata.currentNodeId}`);

    (state as any).metadata.iterations ??= 0;
    (state as any).metadata.consecutiveSameNode ??= 0;

    const maxIterations = options?.maxIterations ?? 1000000;

    try {
      while ((state as any).metadata.iterations < maxIterations) {
        (state as any).metadata.iterations++;
        
        throwIfAborted(state, 'Graph execution aborted');

        if ((state as any).metadata.waitingForUser && (state as any).metadata.currentNodeId === 'input_handler') {
          console.log('[Graph] Waiting for user at input_handler → forcing end');
          break;
        }

        const node = this.nodes.get((state as any).metadata.currentNodeId);
        if (!node) throw new Error(`Node missing: ${(state as any).metadata.currentNodeId}`);

        console.log(`[Graph] → ${node.name} (${(state as any).metadata.currentNodeId})`);
        const result: NodeResult<TState> = await node.execute(state);

        state = result.state;

        // Check abort immediately after node execution
        throwIfAborted(state, 'Graph execution aborted');

        // yield to event loop
        await new Promise(r => setTimeout(r, 0));

        const currentNodeId = String((state as any).metadata.currentNodeId || '');
        let nextId = this.resolveNext(currentNodeId, result.decision, state);
        console.log(`[Graph] ${result.decision.type} → ${nextId}`);

        if (nextId === currentNodeId) {
          (state as any).metadata.consecutiveSameNode++;
          if ((state as any).metadata.consecutiveSameNode >= MAX_CONSECTUIVE_LOOP) {
            if (currentNodeId === 'action') {
              console.warn('Max consecutive loop on action — forcing critic review');
              (state as any).metadata.consecutiveSameNode = 0;
              nextId = 'skill_critic';
            } else {
              console.warn(`Max consecutive loop — forcing end`);
              break;
            }
          }
        } else {
          (state as any).metadata.consecutiveSameNode = 0;
        }

        if (nextId === 'end' || (this.endPoints.has((state as any).metadata.currentNodeId) && result.decision.type === 'end')) {
          console.log(`[Graph] Complete after ${(state as any).metadata.iterations} iterations`);
          break;
        }

        (state as any).metadata.currentNodeId = nextId;
      }
    } catch (error: any) {
      console.log('[Graph] Execution stopped:', error);
      // Don't re-throw AbortError, just log and continue to send completion signal
      if (error?.name === 'AbortError') {
        console.log('[Graph] Graph execution aborted by user');
      } else {
        // Re-throw non-abort errors
        throw error;
      }
    }

    if ((state as any).metadata.iterations >= maxIterations) {
      console.warn('Max iterations hit');
      (state as any).metadata.maxIterationsReached = true;
    }

    // Always send completion signal, whether completed naturally or aborted
    console.log('[Graph] Sending graph_execution_complete signal');
    const ws = getWebSocketClientService();
    const connId = (state as any).metadata.wsChannel || 'dreaming-protocol';
    ws.send(connId, {
      type: 'transfer_data',
      data: { role: 'system', content: 'graph_execution_complete' },
    });

    return state;
  }

  /**
   * Resolve next node based on decision and edges.
   * @param current - Current node ID
   * @param decision - Node's returned decision
   * @param state - Current state
   * @returns Next node ID or 'end'
   */
  private resolveNext(current: string, decision: NodeDecision, state: TState): string {
    console.log(`[Graph] resolveNext: current=${current}, decision=${decision.type}`);
    
    switch (decision.type) {
      case 'end': return 'end';
      case 'goto':
        if (this.nodes.has(decision.nodeId)) return decision.nodeId;
        console.warn(`Invalid goto: ${decision.nodeId}`);
        return 'end';
      case 'continue': return current;
      case 'revise':
        return this.getReviserFor(current) || 'end';
      case 'next':
        const edges = this.edges.get(current) || [];
        console.log(`[Graph] resolveNext: found ${edges.length} edges for ${current}`);
        for (const edge of edges) {
          if (typeof edge.to === 'function') {
            const nextId = edge.to(state);
            console.log(`[Graph] resolveNext: conditional edge resolved to ${nextId}`);
            if (nextId && this.nodes.has(nextId)) return nextId;
          } else if (this.nodes.has(edge.to)) {
            console.log(`[Graph] resolveNext: static edge to ${edge.to}`);
            return edge.to;
          }
        }
        console.log(`[Graph] resolveNext: no valid edges found, ending`);
        return 'end';
    }
  }

  /**
   * Get reviser node for revise decisions (stub - customize per graph).
   */
  private getReviserFor(nodeId: string): string | null {
    if (nodeId.includes('executor')) return 'planner';
    if (nodeId.includes('critic') || nodeId.includes('planner')) return 'strategic_planner';
    return null;
  }

  /**
   * Clean up all nodes.
   */
  async destroy(): Promise<void> {
    for (const node of this.nodes.values()) {
      if (node.destroy) await node.destroy();
    }
    this.nodes.clear();
    this.edges.clear();
    this.initialized = false;
  }
}

/**
 * Create initial thread state with first user message.
 * @param prompt - The initial user message content
 * @param metadata - Optional metadata for the message
 * @returns Fully initialized ThreadState
 */
export async function createInitialThreadState<T extends BaseThreadState>(
  prompt: string,
  overrides: Partial<T['metadata']> = {}
): Promise<T> {

  const now = Date.now();
  const msgId = nextMessageId();
  
  const mode = await SullaSettingsModel.get('modelMode', 'local');
  const llmModel = mode === 'remote' ? await SullaSettingsModel.get('remoteModel', 'grok-4-1-fast-reasoning') : await SullaSettingsModel.get('sullaModel', 'tinyllama:latest');
  const llmLocal = mode === 'local';
  
  const baseMetadata: BaseThreadState['metadata'] = {
      action: 'direct_answer',  // Default action for initial state
      threadId: overrides.threadId ?? nextThreadId(),
      wsChannel: overrides.wsChannel ?? DEFAULT_WS_CHANNEL,
      llmModel,
      llmLocal,
      cycleComplete: false,
      waitingForUser: false,
      options: overrides.options ?? { abort: undefined },
      currentNodeId: overrides.currentNodeId ?? 'input_handler',
      consecutiveSameNode: 0,
      iterations: 0,
      revisionCount: 0,
      maxIterationsReached: false,
      memory: overrides.memory ?? {
        knowledgeBaseContext: '',
        chatSummariesContext: ''
      },
      subGraph: {
        state: 'completed',
        name: 'hierarchical',
        prompt: '',
        response: ''
      },
      finalSummary: '',
      totalSummary: '',
      finalState: 'running',
      n8nLiveEventsEnabled: false,
      returnTo: null
    };

  const result = {
      messages: [{
        id: msgId,
        role: 'user',
        content: prompt.trim(),
        timestamp: now,
        metadata: {
          type: 'initial_prompt',
          source: 'user'
        }
      }],
      metadata: {
        ...baseMetadata,
        ...overrides
      }
    };

  return result as unknown as T;
}

let messageCounter = 0;
let threadCounter = 0;

export function nextMessageId(): string {
  return `msg_${Date.now()}_${++messageCounter}`;
}

export function nextThreadId(): string {
  return `thread_${Date.now()}_${++threadCounter}`;
}

class OverlordSkillGraphRunnerNode implements GraphNode<OverlordThreadState> {
  id = 'skill_graph_runner';
  name = 'Skill Graph Runner';

  async execute(state: OverlordThreadState): Promise<NodeResult<OverlordThreadState>> {
    // Allow the delegated SkillGraph cycle to execute each loop.
    state.metadata.cycleComplete = false;
    state.metadata.waitingForUser = false;

    const skillGraph = createSkillGraph();
    await skillGraph.execute(state as unknown as SkillGraphState, 'input_handler');
    await skillGraph.destroy();

    return { state, decision: { type: 'next' } };
  }
}

// ============================================================================
//
// Graph Decision Trees
//
//
//
// ============================================================================

/**
 * Create a specialized graph for heartbeat-triggered OverLord planning
 * This graph handles autonomous strategic oversight during idle periods
 */
export function createOverlordGraph(): Graph<OverlordThreadState> {

  // Create lightweight heartbeat graph with only core nodes
  const graph = new Graph<OverlordThreadState>();

  graph.addNode(new InputHandlerNode<OverlordThreadState>());
  graph.addNode(new OverLordPlannerNode());  // id: 'overlord_planner'
  graph.addNode(new OverlordSkillGraphRunnerNode()); // id: 'skill_graph_runner'

  // Entry point
  graph.addEdge('input_handler', 'overlord_planner');

  // OverLord core loop: think → run skill graph → loop or end
  graph.addConditionalEdge('overlord_planner', state => {
    const v = state.metadata;
    const overlordLoopCount = (((v as any).overlordLoopCount ?? 0) + 1);
    (v as any).overlordLoopCount = overlordLoopCount;

    // End if you want
    if (v?.projectState === 'end') return 'end';

    // Hard stop after 20 overlord recursions
    if (overlordLoopCount >= 20) return 'end';

    // Delegate one cycle to the SkillGraph each loop.
    return 'skill_graph_runner';
  });

  // Skill graph execution returns control to overlord planner.
  graph.addEdge('skill_graph_runner', 'overlord_planner');

  graph.setEntryPoint('input_handler');
  graph.setEndPoints('overlord_planner');

  return graph;
}

/**
 * Create a skill-aware ReAct graph for intelligent planning and execution.
 * 
 * This graph combines planning with a reasoning-action loop that can:
 * - Load and follow skill templates (SOPs)
 * - Track progress with evidence-based verification
 * - Execute actions with full tool access via BaseNode
 * - Maintain skill compliance and step verification
 * 
 * Flow: Input → PlanRetrieval → Planner → Reasoning ↔ Action (loop until complete)
 * 
 * Features:
 * - Skill template integration for guided execution
 * - Evidence-based task verification
 * - Progress tracking with completed/pending step separation
 * - ActivePlanManager integration for heartbeats
 * - Quality inspection before marking tasks complete
 * 
 * @returns {Graph} Fully configured skill-aware ReAct graph
 */
export function createSkillGraph(): Graph<SkillGraphState> {
  const graph = new Graph<SkillGraphState>();

  // Add all required nodes
  graph.addNode(new InputHandlerNode());     // id: 'input_handler'
  graph.addNode(new PlanRetrievalNode());    // id: 'plan_retrieval' 
  graph.addNode(new PlannerNode());          // id: 'planner' (skill-aware planning)
  graph.addNode(new ReasoningNode());        // id: 'reasoning'
  graph.addNode(new ActionNode());          // id: 'action'
  graph.addNode(new SkillCriticNode());         // id: 'skill_critic'
  graph.addNode(new OutputNode());              // id: 'output' (skill-aware completion)

  // Sequential entry: Input → PlanRetrieval
  graph.addEdge('input_handler', 'plan_retrieval');

  // PlanRetrieval complexity routing:
  // - low: direct to output
  // - medium or high WITHOUT a skill: direct to action (executor)
  // - high WITH a skill identified: full planner flow
  graph.addConditionalEdge('plan_retrieval', state => {
    const complexity = (state.metadata as any).planRetrieval?.complexity;
    const selectedSkillSlug = (state.metadata as any).planRetrieval?.selected_skill_slug;
    const hasSkill = typeof selectedSkillSlug === 'string' && selectedSkillSlug.trim().length > 0;

    if (complexity === 'low') {
      console.log('[SkillGraph] PlanRetrieval complexity=low - routing directly to output');
      return 'output';
    }

    if (complexity === 'high' && hasSkill) {
      console.log(`[SkillGraph] PlanRetrieval complexity=high + skill=${selectedSkillSlug} - routing to planner`);
      return 'planner';
    }

    console.log(`[SkillGraph] PlanRetrieval complexity=${complexity}, skill=${selectedSkillSlug || 'none'} - routing directly to action`);
    return 'action';
  });

  // Planner → Reasoning (start ReAct loop)
  // Planner always produces a PRD stored at planning_instructions.
  // If PRD generation failed, retry up to MAX_PLANNER_RETRIES times.
  graph.addConditionalEdge('planner', state => {
    const planningInstructions = (state.metadata as any).planning_instructions;

    console.log('[SkillGraph] Planner routing:');
    console.log(`[SkillGraph] - planning_instructions: ${planningInstructions ? planningInstructions.length + ' chars' : 'none'}`);

    // PRD not generated — retry planner
    if (!planningInstructions) {
      const plannerRetries = (state.metadata as any).plannerRetries || 0;

      if (plannerRetries < MAX_PLANNER_RETRIES) {
        (state.metadata as any).plannerRetries = plannerRetries + 1;
        console.log(`[SkillGraph] PRD not generated (attempt ${plannerRetries + 1}/${MAX_PLANNER_RETRIES + 1}) - retrying planner`);
        return 'planner';
      } else {
        console.log(`[SkillGraph] Planner failed after ${MAX_PLANNER_RETRIES + 1} attempts - proceeding to output with failure`);
        return 'output';
      }
    }

    console.log('[SkillGraph] PRD ready - starting ReAct loop');
    return 'reasoning';
  });

  // ReAct Loop: Reasoning ↔ Action with loop counter and critic intervention
  graph.addConditionalEdge('reasoning', state => {
    const technicalInstructions = (state.metadata as any).technical_instructions;

    // Keep reasoning until it produces a technical instruction response.
    if (!technicalInstructions) {
      const reasoningRetries = (state.metadata as any).reasoningRetries || 0;

      if (reasoningRetries >= MAX_REASONING_RETRIES) {
        console.log(`[SkillGraph] Reasoning hit retry cap (${MAX_REASONING_RETRIES}) - proceeding to output`);
        return 'output';
      }

      (state.metadata as any).reasoningRetries = reasoningRetries + 1;
      console.log('[SkillGraph] No technical_instructions yet - retrying reasoning');
      return 'reasoning';
    }

    // Reset retry counter after successful reasoning output.
    (state.metadata as any).reasoningRetries = 0;

    console.log('[SkillGraph] Proceeding to action execution');
    return 'action';
  });
  
  // Action completes → always route through critic for verification (no bypasses)
  graph.addConditionalEdge('action', state => {
    const actionMeta = (state.metadata as any).action || {};
    const actionStatus = String(actionMeta.status || '').trim().toLowerCase();
    const actionResponse = actionMeta.response;

    if (actionStatus === 'blocked') {
      console.log('[SkillGraph] Action reported BLOCKED - routing back to reasoning and skipping critic');
      (state.metadata as any).reactLoopCount = 0;
      return 'reasoning';
    }

    if (actionResponse) {
      console.log('[SkillGraph] Action response captured - sending to critic for verification');
      return 'skill_critic';
    }

    // Initialize or increment loop counter
    const currentLoopCount = (state.metadata as any).reactLoopCount || 0;
    const newLoopCount = currentLoopCount + 1;
    (state.metadata as any).reactLoopCount = newLoopCount;

    // After MAX_ACTION_LOOPS cycles, send to critic for evaluation
    if (newLoopCount >= MAX_ACTION_LOOPS) {
      console.log(`[SkillGraph] ${newLoopCount} ReAct cycles completed - sending to critic for evaluation`);
      return 'skill_critic';
    }

    console.log(`[SkillGraph] Action completed (cycle ${newLoopCount}) - continuing action loop`);
    return 'action';
  });
  
  // Critic evaluation → routing based on technical/project completion
  graph.addConditionalEdge('skill_critic', state => {
    const criticData = (state.metadata as any).skillCritic;
    
    if (!criticData) {
      console.log('[SkillGraph] No critic decision - defaulting to output');
      return 'output';
    }

    const technicalCompleted = criticData.technical_completed === true;
    const projectCompleted = criticData.project_complete === true;

    if (technicalCompleted && projectCompleted) {
      console.log('[SkillGraph] Critic: Technical and project complete - proceeding to output');
      return 'output';
    }

    if (!technicalCompleted) {
      console.log('[SkillGraph] Critic: Technical incomplete - returning to reasoning with technical feedback');
      (state.metadata as any).reactLoopCount = 0;
      (state.metadata as any).reasoning = {
        ...((state.metadata as any).reasoning || {}),
        critic_feedback: criticData.technical_feedback || '',
      };
      return 'reasoning';
    }

    console.log('[SkillGraph] Critic: Technical complete but project incomplete - returning to reasoning with project feedback');
    (state.metadata as any).reactLoopCount = 0;
    (state.metadata as any).reasoning = {
      ...((state.metadata as any).reasoning || {}),
      critic_feedback: criticData.project_feedback || '',
    };
    return 'reasoning';
  });

  // Output can loop back to input for continued work
  graph.addConditionalEdge('output', state => {
    const shouldContinue = (state.metadata as any).cycleComplete === false;
    return shouldContinue ? 'input_handler' : 'end';
  });

  // Set entry and end points
  graph.setEntryPoint('input_handler');
  graph.setEndPoints('output');

  return graph;
}
